{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13893027,"sourceType":"datasetVersion","datasetId":8851140}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1a. **CLASSIFICAZIONE**","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# CELL 1 - IMPORT E SETUP\n# ============================================================\nimport os\nimport random\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport time\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as T\nfrom torchvision import models\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report, balanced_accuracy_score\nimport seaborn as sns\n\n# âœ… SEED PER RIPRODUCIBILITÃ€\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed(SEED)\ntorch.backends.cudnn.deterministic = True\n\nprint(\"Librerie importate e Seed impostato.\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================\n# CELL 2 - CONFIGURAZIONE\n# ============================================================\n\n# Percorsi (Adatta se necessario)\nEXCEL_PATH = \"/kaggle/input/tumor-segmentation-ai/training_metadata.xlsx\"\nIMAGES_ROOT = \"/kaggle/input/tumor-segmentation-ai/training_images/training_images\"\n\n# âš™ï¸ IPERPARAMETRI OTTIMIZZATI PER EFFICIENTNET-B7\n# B7 lavora nativamente a 600x600, ma 300 Ã¨ un buon compromesso memoria/performance\nIMG_SIZE = 300          \nBATCH_SIZE = 24          # Abbassato a 8 per evitare OutOfMemory con B7\nNUM_WORKERS = 2\nNUM_CLASSES = 3\n\n# Mappatura\nid2class = {0: \"benigno\", 1: \"maligno\", 2: \"sano\"}\nclass2id = {v: k for k, v in id2class.items()}\n\n# Device Check\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Configurazione: IMG_SIZE={IMG_SIZE}, BATCH={BATCH_SIZE}\")\nprint(\"Esecuzione su:\", device)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================\n# CELL 3 - DATA LOADING & LOSS WEIGHTS\n# ============================================================\n\ndf = pd.read_excel(EXCEL_PATH)\nIMG_COL = \"US\"\nLABEL_COL = \"LABEL\"\n\n# Pulizia\ndf = df.dropna(subset=[IMG_COL, LABEL_COL]).reset_index(drop=True)\nprint(f\"Dataset caricato: {len(df)} immagini totali.\")\n\n# Visualizzazione Distribuzione\ncounts = df[LABEL_COL].value_counts().sort_index()\nprint(\"\\nDistribuzione Classi:\")\nprint(counts)\n\n# ðŸ”¥ CALCOLO PESI PER LA LOSS (Weighted CrossEntropy)\n# Serve per bilanciare le classi (Maligno Ã¨ meno frequente di Benigno)\n# Formula inversa: Peso = 1 / Frequenza (normalizzato)\nclass_counts = counts.values\ntotal_samples = sum(class_counts)\nclass_weights = [total_samples / (len(class_counts) * c) for c in class_counts]\n\n# Convertiamo in tensor e spostiamo su GPU\nclass_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)\nprint(f\"\\nPesi calcolati per la Loss: {class_weights_tensor.cpu().numpy()}\")\n# Esempio output atteso: [0.7, 1.3, 1.0] -> Il modello verrÃ  \"punito\" di piÃ¹ se sbaglia i Maligni\n\nplt.figure(figsize=(5,4))\ncounts.plot(kind=\"bar\", color=['#4c72b0', '#c44e52', '#55a868'])\nplt.xticks(ticks=[0,1,2], labels=[id2class[i] for i in [0,1,2]], rotation=0)\nplt.title(\"Bilanciamento Classi\")\nplt.grid(axis=\"y\", alpha=0.3)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================\n# CELL 4 - DATASET & DATALOADER (FIX: DROP_LAST=TRUE)\n# ============================================================\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nimport cv2\n\n# 1. DEFINIZIONE DATASET\nclass UltrasoundDataset(Dataset):\n    def __init__(self, df, img_col, label_col, root=\"\", transform=None):\n        self.df = df.reset_index(drop=True)\n        self.img_col = img_col\n        self.label_col = label_col\n        self.root = root\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n\n    def _get_img_path(self, idx):\n        path_str = str(self.df.loc[idx, self.img_col])\n        if self.root:\n            return os.path.join(self.root, path_str)\n        return path_str\n\n    def __getitem__(self, idx):\n        img_path = self._get_img_path(idx)\n        label = int(self.df.loc[idx, self.label_col])\n        \n        try:\n            # Carichiamo come RGB\n            pil_img = Image.open(img_path).convert(\"RGB\")\n            # Convertiamo in Numpy per Albumentations\n            img_np = np.array(pil_img)\n        except Exception as e:\n            print(f\"Errore caricamento {img_path}: {e}\")\n            img_np = np.zeros((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)\n\n        if self.transform:\n            augmented = self.transform(image=img_np)\n            img = augmented['image']\n        else:\n            img = T.ToTensor()(pil_img)\n            \n        return img, label\n\n# 2. TRASFORMAZIONI (CLAHE + ELASTIC)\ntrain_transform = A.Compose([\n    A.Resize(IMG_SIZE, IMG_SIZE),\n    A.CLAHE(clip_limit=4.0, tile_grid_size=(8, 8), p=0.5),\n    A.ElasticTransform(alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03, p=0.3),\n    A.HorizontalFlip(p=0.5),\n    A.VerticalFlip(p=0.5),\n    A.Rotate(limit=20, p=0.5),\n    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    ToTensorV2()\n])\n\nval_transform = A.Compose([\n    A.Resize(IMG_SIZE, IMG_SIZE),\n    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    ToTensorV2()\n])\n\n# 3. DATALOADER (CON FIX)\ntrain_df, val_df = train_test_split(df, stratify=df[LABEL_COL], test_size=0.2, random_state=SEED)\nprint(\"Train size:\", len(train_df), \"Val size:\", len(val_df))\n\ntrain_ds = UltrasoundDataset(train_df, IMG_COL, LABEL_COL, IMAGES_ROOT, train_transform)\nval_ds = UltrasoundDataset(val_df, IMG_COL, LABEL_COL, IMAGES_ROOT, val_transform)\n\n# ðŸ”¥ FIX QUI: drop_last=True\n# Scarta l'ultimo batch se Ã¨ incompleto (es. 2 immagini), evitando che le GPU ne ricevano 1 sola e crashino.\ntrain_loader = DataLoader(\n    train_ds, \n    batch_size=BATCH_SIZE, \n    shuffle=True, \n    num_workers=NUM_WORKERS, \n    pin_memory=True, \n    drop_last=True  # <--- FONDAMENTALE PER 2 GPU\n)\n\nval_loader = DataLoader(\n    val_ds, \n    batch_size=BATCH_SIZE, \n    shuffle=False, \n    num_workers=NUM_WORKERS, \n    pin_memory=True, \n    drop_last=False # In validazione non serve (non aggiorniamo i pesi BatchNorm)\n)\n\nprint(\"âœ… Dataloader corretti (drop_last=True attivato).\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================\n# CELL 5 - MODELLO EFFICIENTNET-B7 (FIXED INPLACE ERROR)\n# ============================================================\n\ndef get_model():\n    print(\"Scaricamento pesi EfficientNet-B7...\")\n    weights = models.EfficientNet_B7_Weights.DEFAULT\n    model = models.efficientnet_b7(weights=weights)\n\n    # Output features di B7 (solitamente 2560)\n    in_features = model.classifier[1].in_features\n    \n    # --- TESTA AVANZATA (Bottleneck) ---\n    model.classifier = nn.Sequential(\n        # 1. Normalizza le feature in uscita dal backbone\n        nn.BatchNorm1d(in_features),\n        \n        # 2. Layer Intermedio (Bottleneck)\n        nn.Linear(in_features, 512),\n        nn.ReLU(),\n        \n        # 3. Dropout (FIX: inplace=False per evitare RuntimeError)\n        nn.Dropout(p=0.5, inplace=False), \n        \n        # 4. Layer Finale\n        nn.Linear(512, NUM_CLASSES)\n    )\n    \n    # Sblocca tutti i parametri\n    for param in model.parameters():\n        param.requires_grad = True\n    \n    return model\n\n# 1. Istanzia il modello\nmodel = get_model()\n\n# 2. Configura Dual GPU\nif torch.cuda.device_count() > 1:\n    print(f\"ðŸ”¥ {torch.cuda.device_count()} GPU rilevate! Attivazione DataParallel.\")\n    model = nn.DataParallel(model)\nelse:\n    print(\"âš ï¸ Una sola GPU rilevata.\")\n\n# 3. Sposta su Device\nmodel = model.to(device)\n\nprint(\"Modello B7 con Bottleneck Head pronto (Inplace Error Fixed).\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================\n# CELL 6 - TRAINING LOOP COMPLETO (DUAL GPU + LOGGING BATCH)\n# ============================================================\nimport time\n\n# --- 1. DEFINIZIONE FUNZIONI DI SUPPORTO ---\ndef train_one_epoch(model, loader, criterion, optimizer, epoch_idx, total_epochs):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    \n    # Aggiunto enumerate per avere l'indice del batch\n    for i, (inputs, labels) in enumerate(loader):\n        inputs, labels = inputs.to(device), labels.to(device)\n        \n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item() * inputs.size(0)\n        preds = outputs.argmax(1)\n        correct += (preds == labels).sum().item()\n        total += labels.size(0)\n        \n        # ðŸŸ¢ PRINT INTERMEDIO OGNI 10 BATCH\n        if (i + 1) % 10 == 0:\n            print(f\"    [Epoca {epoch_idx+1}/{total_epochs}] Batch {i+1}/{len(loader)} -> Loss: {loss.item():.4f}\")\n        \n    return running_loss / total, correct / total\n\ndef validate(model, loader, criterion):\n    model.eval()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    y_true, y_pred = [], []\n    \n    with torch.no_grad():\n        for inputs, labels in loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            \n            running_loss += loss.item() * inputs.size(0)\n            preds = outputs.argmax(1)\n            correct += (preds == labels).sum().item()\n            total += labels.size(0)\n            \n            y_true.extend(labels.cpu().numpy())\n            y_pred.extend(preds.cpu().numpy())\n            \n    return running_loss / total, correct / total, balanced_accuracy_score(y_true, y_pred)\n\n# --- 2. CONFIGURAZIONE OTTIMIZZATORE PER DUAL GPU ---\n\n# Controllo se il modello Ã¨ in DataParallel per accedere ai parametri corretti\nif hasattr(model, 'module'):\n    print(\"Configurazione parametri per Dual GPU (model.module)...\")\n    backbone_params = model.module.features.parameters()\n    head_params = model.module.classifier.parameters()\nelse:\n    print(\"Configurazione parametri per Single GPU...\")\n    backbone_params = model.features.parameters()\n    head_params = model.classifier.parameters()\n\n# Differential Learning Rates\noptimizer = optim.AdamW([\n    {'params': backbone_params, 'lr': 1e-5}, # Backbone lento\n    {'params': head_params, 'lr': 1e-3}      # Testa veloce\n], weight_decay=1e-2)\n\ncriterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=5)\n\n# --- 3. AVVIO TRAINING LOOP ---\nNUM_EPOCHS = 60\nbest_bal_acc = 0\npatience_counter = 0\nEARLY_STOP_PATIENCE = 15\n\nhistory = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_bal_acc': []}\n\nprint(f\"\\nðŸš€ Avvio Training su {torch.cuda.device_count()} GPU\")\n\nfor epoch in range(NUM_EPOCHS):\n    start_time = time.time()\n    \n    # Train (Passiamo anche l'indice epoca per il print)\n    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, epoch, NUM_EPOCHS)\n    \n    # Validation\n    val_loss, val_acc, val_bal_acc = validate(model, val_loader, criterion)\n    \n    # Scheduler Update\n    scheduler.step(val_bal_acc)\n    \n    # Recupero LR corrente\n    current_lr_head = optimizer.param_groups[1]['lr']\n    \n    # Salvataggio storico\n    history['train_loss'].append(train_loss)\n    history['train_acc'].append(train_acc)\n    history['val_loss'].append(val_loss)\n    history['val_bal_acc'].append(val_bal_acc)\n    \n    epoch_time = time.time() - start_time\n    \n    print(f\"ðŸ”µ FINE EPOCA {epoch+1}/{NUM_EPOCHS} [{epoch_time:.0f}s] | LR Head: {current_lr_head:.1e}\")\n    print(f\"   Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\") \n    print(f\"   Val Loss:   {val_loss:.4f} | Val Bal Acc: {val_bal_acc:.4f}\")\n    \n    # Checkpoint\n    if val_bal_acc > best_bal_acc:\n        best_bal_acc = val_bal_acc\n        \n        # Salvataggio compatibile\n        if hasattr(model, 'module'):\n            torch.save(model.module.state_dict(), \"best_model_b7_dual.pt\")\n        else:\n            torch.save(model.state_dict(), \"best_model_b7_dual.pt\")\n            \n        print(\"   âœ“ Miglioramento! Modello salvato.\")\n        patience_counter = 0\n    else:\n        patience_counter += 1\n        print(f\"   No improvement ({patience_counter}/{EARLY_STOP_PATIENCE})\")\n        if patience_counter >= EARLY_STOP_PATIENCE:\n            print(\"   âŒ Early Stopping attivato.\")\n            break\n\nprint(f\"\\nðŸ† Training completato. Best Balanced Acc: {best_bal_acc:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================\n# CELL 7 - GRAFICI\n# ============================================================\nplt.figure(figsize=(12, 5))\n\nplt.subplot(1, 2, 1)\nplt.plot(history['train_loss'], label='Train Loss')\nplt.plot(history['val_loss'], label='Val Loss')\nplt.title(\"Loss During Fine-Tuning\")\nplt.xlabel(\"Epoch\")\nplt.legend()\nplt.grid(True, alpha=0.3)\n\nplt.subplot(1, 2, 2)\nplt.plot(history['train_acc'], label='Train Acc')\nplt.plot(history['val_bal_acc'], label='Val Balanced Acc')\nplt.title(\"Balanced Accuracy During Fine-Tuning\")\nplt.xlabel(\"Epoch\")\nplt.legend()\nplt.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================\n# CELL 8 - VALUTAZIONE DETTAGLIATA\n# ============================================================\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport seaborn as sns\n\n# 1. Carica il miglior modello salvato\n# Ricostruiamo il modello pulito (senza DataParallel wrapper per il caricamento)\nmodel_eval = get_model() \n\n# Se abbiamo salvato con model.module.state_dict(), le chiavi sono pulite\n# Se abbiamo salvato con model.state_dict() e DataParallel, potrebbero avere prefisso 'module.'\nstate_dict = torch.load(\"best_model_b7_dual.pt\", map_location=device)\n\n# Pulizia chiavi se necessario (rimuove 'module.' se presente)\nnew_state_dict = {}\nfor k, v in state_dict.items():\n    name = k.replace(\"module.\", \"\") \n    new_state_dict[name] = v\n\nmodel_eval.load_state_dict(new_state_dict)\nmodel_eval = model_eval.to(device)\nmodel_eval.eval()\n\nprint(\"Best Model caricato per la valutazione.\")\n\n# 2. Predizioni su tutto il Validation Set\ny_true, y_pred = [], []\ny_probs = []\n\nprint(\"Generazione predizioni...\")\nwith torch.no_grad():\n    for inputs, labels in val_loader:\n        inputs = inputs.to(device)\n        outputs = model_eval(inputs)\n        \n        # Salviamo le probabilitÃ  per la ROC curve (opzionale) o TTA\n        probs = torch.softmax(outputs, dim=1)\n        preds = outputs.argmax(1)\n        \n        y_true.extend(labels.cpu().numpy())\n        y_pred.extend(preds.cpu().numpy())\n        y_probs.extend(probs.cpu().numpy())\n\n# 3. Report Testuale\nprint(\"\\n--- CLASSIFICATION REPORT ---\")\nprint(classification_report(y_true, y_pred, target_names=[id2class[i] for i in range(3)]))\n\n# 4. Matrice di Confusione Grafica\ncm = confusion_matrix(y_true, y_pred)\nplt.figure(figsize=(6, 5))\nsns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", \n            xticklabels=id2class.values(), yticklabels=id2class.values())\nplt.title(f\"Confusion Matrix (Best Bal Acc: {0.8410:.2%})\")\nplt.xlabel(\"Predetto\")\nplt.ylabel(\"Reale\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================\n# CELL 9 - TEST TIME AUGMENTATION (TTA)\n# ============================================================\n\ndef predict_tta(model, loader):\n    model.eval()\n    all_probs = []\n    all_labels = []\n    \n    print(\"Esecuzione TTA (Original + Flip H + Flip V)...\")\n    \n    with torch.no_grad():\n        for inputs, labels in loader:\n            inputs = inputs.to(device)\n            all_labels.extend(labels.cpu().numpy())\n            \n            # 1. Predizione Originale\n            out1 = model(inputs)\n            prob1 = torch.softmax(out1, dim=1)\n            \n            # 2. Predizione Flip Orizzontale\n            inputs_h = torch.flip(inputs, dims=[3]) # 3 Ã¨ l'asse width\n            out2 = model(inputs_h)\n            prob2 = torch.softmax(out2, dim=1)\n            \n            # 3. Predizione Flip Verticale\n            inputs_v = torch.flip(inputs, dims=[2]) # 2 Ã¨ l'asse height\n            out3 = model(inputs_v)\n            prob3 = torch.softmax(out3, dim=1)\n            \n            # MEDIA DELLE PROBABILITÃ€\n            avg_prob = (prob1 + prob2 + prob3) / 3.0\n            all_probs.extend(avg_prob.cpu().numpy())\n            \n    return np.array(all_labels), np.array(all_probs)\n\n# Esegui TTA\ny_true_tta, y_probs_tta = predict_tta(model_eval, val_loader)\ny_pred_tta = np.argmax(y_probs_tta, axis=1)\n\n# Calcola nuova accuracy\ntta_acc = balanced_accuracy_score(y_true_tta, y_pred_tta)\nprint(f\"\\nðŸš€ Balanced Accuracy senza TTA: 0.8410\")\nprint(f\"ðŸ”¥ Balanced Accuracy CON TTA:    {tta_acc:.4f}\")\n\n# Mostra se Ã¨ migliorata la matrice\nprint(\"\\nClassification Report (TTA):\")\nprint(classification_report(y_true_tta, y_pred_tta, target_names=[id2class[i] for i in range(3)]))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **1b Segementazione**","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# CELL 1 - SETUP AMBIENTE E LIBRERIE SOTA\n# ============================================================\n# Installiamo la libreria standard per la segmentazione avanzata\n!pip install segmentation_models_pytorch -q\n\nimport os\nimport random\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom sklearn.model_selection import train_test_split\nimport segmentation_models_pytorch as smp\n\n# SEED PER RIPRODUCIBILITÃ€ TOTALE\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed(SEED)\ntorch.backends.cudnn.deterministic = True\n\n# CONFIGURAZIONE\nEXCEL_PATH = \"/kaggle/input/tumor-segmentation-ai/training_metadata.xlsx\"\nIMAGES_ROOT = \"/kaggle/input/tumor-segmentation-ai/training_images/training_images\"\nIMG_SIZE = 256       # Standard aureo per U-Net/MAnet\nBATCH_SIZE = 16      # Con 2 GPU T4 va bene (8 img per GPU)\nNUM_EPOCHS = 50\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nprint(f\"âœ… Setup MAnet pronto su {device}.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================\n# CELL 2 - DATA PREPARATION (LEAKAGE-PROOF)\n# ============================================================\n\n# 1. Carica il DataFrame COMPLETO (Come nel Notebook 1)\ndf_full = pd.read_excel(EXCEL_PATH)\ndf_full = df_full.dropna(subset=['US', 'LABEL', 'MASK']).reset_index(drop=True)\n\n# 2. SPLIT SUL COMPLETO (Stesso Seed = Stesso Split del Classificatore)\n# Questo garantisce che train_full e val_full siano identici a quelli del Notebook 1\ntrain_full, val_full = train_test_split(df_full, stratify=df_full['LABEL'], test_size=0.2, random_state=SEED)\n\nprint(f\"Split Iniziale (Identico al Classificatore):\")\nprint(f\"  Train Totale: {len(train_full)}\")\nprint(f\"  Val Totale:   {len(val_full)}\")\n\n# 3. FILTRO POST-SPLIT (Solo ora rimuoviamo i Normali)\n# Manteniamo solo Benign (0) e Malignant (1) DAI RISPETTIVI SET\ntrain_seg = train_full[train_full['LABEL'] != 2].reset_index(drop=True)\nval_seg = val_full[val_full['LABEL'] != 2].reset_index(drop=True)\n\nprint(f\"\\nDataset Segmentazione Filtrato (Solo B/M):\")\nprint(f\"  Train Seg: {len(train_seg)} (Sicuro: era nel Train del Classificatore)\")\nprint(f\"  Val Seg:   {len(val_seg)}   (Sicuro: mai visto da nessuno dei due)\")\n\n# 4. Dataset Class (Identica a prima)\nclass SegmentationDataset(Dataset):\n    def __init__(self, df, root, transform=None):\n        self.df = df # Non serve reset_index qui perchÃ© lo abbiamo fatto sopra\n        self.root = root\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        img_path = os.path.join(self.root, str(self.df.loc[idx, \"US\"]))\n        mask_path = os.path.join(self.root, str(self.df.loc[idx, \"MASK\"]))\n        \n        try:\n            image = np.array(Image.open(img_path).convert(\"RGB\"))\n            mask = np.array(Image.open(mask_path).convert(\"L\"))\n        except:\n            image = np.zeros((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)\n            mask = np.zeros((IMG_SIZE, IMG_SIZE), dtype=np.uint8)\n\n        mask = np.where(mask > 0, 1.0, 0.0).astype(np.float32)\n\n        if self.transform:\n            aug = self.transform(image=image, mask=mask)\n            image = aug['image']\n            mask = aug['mask']\n            \n        mask = mask.unsqueeze(0) \n        return image, mask\n\n# 5. Augmentation (Copia quella di prima)\ntrain_transform = A.Compose([\n    A.Resize(IMG_SIZE, IMG_SIZE),\n    A.HorizontalFlip(p=0.5),\n    A.VerticalFlip(p=0.5),\n    A.Rotate(limit=20, p=0.5),\n    A.ElasticTransform(alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03, p=0.4),\n    A.GridDistortion(num_steps=5, distort_limit=0.3, p=0.3),\n    A.GaussNoise(var_limit=(10.0, 50.0), p=0.3),\n    A.CLAHE(clip_limit=4.0, tile_grid_size=(8, 8), p=0.3),\n    A.RandomBrightnessContrast(p=0.2),\n    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    ToTensorV2()\n])\n\nval_transform = A.Compose([\n    A.Resize(IMG_SIZE, IMG_SIZE),\n    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    ToTensorV2()\n])\n\n# 6. DATALOADERS (Usiamo i df filtrati post-split)\ntrain_loader = DataLoader(SegmentationDataset(train_seg, IMAGES_ROOT, train_transform), \n                          batch_size=BATCH_SIZE, shuffle=True, num_workers=2, drop_last=True)\nval_loader = DataLoader(SegmentationDataset(val_seg, IMAGES_ROOT, val_transform), \n                        batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n\nprint(\"âœ… Dataloaders pronti. LEAKAGE RISK: 0%.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================\n# CELL 3 - MODELLO MAnet (Multi-scale Attention Net)\n# ============================================================\n\n# MAnet Ã¨ considerata l'erede della Attention U-Net\n# Usa EfficientNet-B7 pre-addestrata su ImageNet come Encoder\n\nENCODER = 'efficientnet-b7'\nENCODER_WEIGHTS = 'imagenet'\nCLASSES = 1\nACTIVATION = None # Usiamo logits grezzi per stabilitÃ  numerica\n\nmodel = smp.MAnet(\n    encoder_name=ENCODER, \n    encoder_weights=ENCODER_WEIGHTS, \n    in_channels=3, \n    classes=CLASSES, \n    activation=ACTIVATION,\n    decoder_pab_channels=64 # Canali per il blocco di attenzione (tuning fine)\n)\n\n# Gestione Multi-GPU\nif torch.cuda.device_count() > 1:\n    print(f\"ðŸ”¥ {torch.cuda.device_count()} GPU attive! DataParallel ON.\")\n    model = nn.DataParallel(model)\n\nmodel = model.to(device)\n\nprint(f\"ðŸš€ Modello MAnet caricato con encoder {ENCODER} pre-addestrato.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================\n# CELL 4 - TRAINING AVANZATO (Con Early Stopping & Batch Monitor)\n# ============================================================\n\n# Definizione Loss Ibrida\nloss_dice = smp.losses.DiceLoss(mode='binary', from_logits=True)\nloss_focal = smp.losses.FocalLoss(mode='binary')\n\ndef criterion(pred, target):\n    # 40% Dice (Forma) + 60% Focal (Pixel difficili)\n    return 0.4 * loss_dice(pred, target) + 0.6 * loss_focal(pred, target)\n\n# Metrica Dice Pura per Valutazione\ndef dice_metric(pred, target):\n    pred = (torch.sigmoid(pred) > 0.5).float()\n    intersection = (pred * target).sum()\n    return (2. * intersection) / (pred.sum() + target.sum() + 1e-7)\n\n# Optimizer & Scheduler\noptimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-3)\n# Scheduler: riduce il LR se ci blocchiamo\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=5, factor=0.5)\n\n# CONFIGURAZIONE EARLY STOPPING\nEARLY_STOP_PATIENCE = 15   # Aspetta 15 epoche senza miglioramenti prima di fermarsi\npatience_counter = 0       # Contatore interno\n\n# Loop\nbest_dice = 0\nhistory = {'train_loss': [], 'train_dice': [], 'val_dice': []}\n\nprint(f\"ðŸš€ Avvio Training MAnet (Stop dopo {EARLY_STOP_PATIENCE} epoche senza miglioramenti)...\")\n\nfor epoch in range(NUM_EPOCHS):\n    model.train()\n    t_loss = 0\n    t_dice = 0\n    \n    # Train Loop con monitoraggio Batch\n    for i, (img, mask) in enumerate(train_loader):\n        img, mask = img.to(device), mask.to(device)\n        \n        optimizer.zero_grad()\n        out = model(img)\n        loss = criterion(out, mask)\n        loss.backward()\n        optimizer.step()\n        \n        loss_val = loss.item()\n        dice_val = dice_metric(out, mask).item()\n        \n        t_loss += loss_val\n        t_dice += dice_val\n        \n        # ðŸŸ¢ PRINT INTERMEDIO OGNI 10 BATCH\n        if (i + 1) % 10 == 0:\n            print(f\"    [Ep {epoch+1}] Batch {i+1}/{len(train_loader)} | Loss: {loss_val:.4f} | Train Dice: {dice_val:.4f}\")\n    \n    # Calcolo Medie Training\n    avg_t_loss = t_loss / len(train_loader)\n    avg_t_dice = t_dice / len(train_loader)\n    \n    # Validation Loop\n    model.eval()\n    v_dice = 0\n    with torch.no_grad():\n        for img, mask in val_loader:\n            img, mask = img.to(device), mask.to(device)\n            out = model(img)\n            v_dice += dice_metric(out, mask).item()\n            \n    avg_v_dice = v_dice / len(val_loader)\n    \n    # Step dello Scheduler (aggiorna LR se necessario)\n    scheduler.step(avg_v_dice)\n    \n    # Salvataggio Storico\n    history['train_loss'].append(avg_t_loss)\n    history['train_dice'].append(avg_t_dice)\n    history['val_dice'].append(avg_v_dice)\n    \n    print(f\"ðŸ”µ FINE EP {epoch+1}/{NUM_EPOCHS} | T. Loss: {avg_t_loss:.4f} | T. Dice: {avg_t_dice:.4f} | Val Dice: {avg_v_dice:.4f}\")\n    \n    # --- LOGICA EARLY STOPPING ---\n    if avg_v_dice > best_dice:\n        best_dice = avg_v_dice\n        # Salvataggio Modello\n        save_obj = model.module.state_dict() if hasattr(model, 'module') else model.state_dict()\n        torch.save(save_obj, \"best_manet_b7.pt\")\n        print(\"  âœ“ Saved Best MAnet Model (New Record!)\")\n        patience_counter = 0 # Resetta contatore perchÃ© abbiamo migliorato\n    else:\n        patience_counter += 1\n        print(f\"  No improvement ({patience_counter}/{EARLY_STOP_PATIENCE})\")\n        \n        if patience_counter >= EARLY_STOP_PATIENCE:\n            print(f\"\\nâŒ EARLY STOPPING ACTIVATED at Epoch {epoch+1}\")\n            print(f\"   Il modello non migliora da {EARLY_STOP_PATIENCE} epoche.\")\n            break\n\nprint(f\"ðŸ† Best Val Dice Score: {best_dice:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================\n# CELL 5 - VISUALIZZAZIONE RISULTATI\n# ============================================================\n# Ricarica modello pulito\nmodel = smp.MAnet(encoder_name=ENCODER, encoder_weights=None, classes=CLASSES, activation=ACTIVATION)\nmodel.load_state_dict(torch.load(\"best_manet_b7.pt\"))\nmodel = model.to(device)\nmodel.eval()\n\nimg, mask = next(iter(val_loader))\nimg, mask = img.to(device), mask.to(device)\n\nwith torch.no_grad():\n    # Sigmoid per probabilitÃ \n    pred_logits = model(img)\n    pred_mask = (torch.sigmoid(pred_logits) > 0.5).float()\n\nplt.figure(figsize=(12, 10))\nfor i in range(4): # Mostra 4 casi\n    # 1. Immagine\n    plt.subplot(4, 3, i*3 + 1)\n    im_np = img[i].cpu().permute(1,2,0).numpy()\n    im_np = im_np * [0.229, 0.224, 0.225] + [0.485, 0.456, 0.406]\n    plt.imshow(np.clip(im_np, 0, 1))\n    plt.title(\"Ultrasound\")\n    plt.axis('off')\n    \n    # 2. Ground Truth\n    plt.subplot(4, 3, i*3 + 2)\n    plt.imshow(mask[i].cpu().squeeze(), cmap='gray')\n    plt.title(\"Ground Truth\")\n    plt.axis('off')\n    \n    # 3. Predizione MAnet\n    plt.subplot(4, 3, i*3 + 3)\n    score = dice_metric(pred_logits[i:i+1], mask[i:i+1]).item()\n    plt.imshow(pred_mask[i].cpu().squeeze(), cmap='gray')\n    plt.title(f\"MAnet Prediction (Dice: {score:.2f})\")\n    plt.axis('off')\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 1 **Classificazione e segmentazione (B/M)**","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# PIPELINE FINALE (Custom Head + MAnet)\n# ============================================================\n!pip install segmentation_models_pytorch -q\n\nimport os\nimport random\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as T\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom sklearn.metrics import classification_report, confusion_matrix, balanced_accuracy_score\nimport segmentation_models_pytorch as smp\nimport seaborn as sns\nfrom torchvision import models\n\n# CONFIGURAZIONE\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nEXCEL_PATH = \"/kaggle/input/tumor-segmentation-ai/training_metadata.xlsx\"\nIMAGES_ROOT = \"/kaggle/input/tumor-segmentation-ai/training_images/training_images\"\n\n# PATH DEI PESI (I tuoi file caricati)\nPATH_CLF = \"/kaggle/input/pesi-modelli/best_model_b7_dual (1).pt\"\nPATH_SEG = \"/kaggle/input/pesi-modelli/best_manet_b7.pt\"\n\n# RISOLUZIONI (Devono combaciare col training)\nIMG_SIZE_CLF = 300 \nIMG_SIZE_SEG = 256\nNUM_CLASSES = 3\nSEED = 42\n\n# MAPPING\nid2class = {0: \"Benign\", 1: \"Malignant\", 2: \"Normal\"}\n\nprint(f\"Pipeline pronta su {DEVICE}.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================\n# CELL 2 - ARCHITETTURE E CARICAMENTO\n# ============================================================\n\n# --- 1. CLASSIFICATORE (La tua architettura Custom) ---\ndef get_classifier():\n    # print(\"Costruzione EfficientNet-B7 con Bottleneck Head...\")\n    # Pesi a None perchÃ© carichiamo i tuoi\n    model = models.efficientnet_b7(weights=None) \n    \n    # Ricostruzione della testa esatta usata nel training\n    in_features = model.classifier[1].in_features\n    \n    model.classifier = nn.Sequential(\n        nn.BatchNorm1d(in_features),\n        nn.Linear(in_features, 512),\n        nn.ReLU(),\n        nn.Dropout(p=0.5, inplace=False), \n        nn.Linear(512, NUM_CLASSES)\n    )\n    return model\n\n# --- 2. SEGMENTATORE (MAnet SOTA) ---\ndef get_segmentor():\n    # Architettura usata nel Notebook 2\n    model = smp.MAnet(\n        encoder_name=\"efficientnet-b7\",\n        encoder_weights=None, \n        in_channels=3,\n        classes=1,\n        activation=None\n    )\n    return model\n\n# --- FUNZIONE DI CARICAMENTO SMART ---\ndef load_weights(model, path):\n    if not os.path.exists(path):\n        print(f\"âŒ ERRORE CRITICO: File non trovato: {path}\")\n        return model\n        \n    print(f\"ðŸ“‚ Caricamento pesi da: {path}\")\n    state_dict = torch.load(path, map_location=DEVICE)\n    \n    # Pulizia delle chiavi (rimuove 'module.' se allenato in DataParallel)\n    new_state_dict = {}\n    for k, v in state_dict.items():\n        name = k.replace(\"module.\", \"\") \n        new_state_dict[name] = v\n        \n    try:\n        model.load_state_dict(new_state_dict)\n        print(\"   -> Pesi caricati correttamente.\")\n    except Exception as e:\n        print(f\"   -> âŒ Errore nel caricamento chiavi: {e}\")\n        \n    return model.to(DEVICE).eval()\n\n# --- INIZIALIZZAZIONE ---\nprint(\"--- Setup Modelli ---\")\n\nclf_model = get_classifier()\nclf_model = load_weights(clf_model, PATH_CLF)\n\nseg_model = get_segmentor()\nseg_model = load_weights(seg_model, PATH_SEG)\n\nprint(\"\\nâœ… Entrambi i modelli sono pronti per la pipeline.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================\n# CELL 3 - DATASET PIPELINE\n# ============================================================\nclass PipelineDataset(Dataset):\n    def __init__(self, df, root):\n        self.df = df.reset_index(drop=True)\n        self.root = root\n        \n        # Per il Classificatore (300x300)\n        self.transform_clf = T.Compose([\n            T.Resize((IMG_SIZE_CLF, IMG_SIZE_CLF)),\n            T.ToTensor(),\n            T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n        ])\n        \n        # Per il Segmentatore (256x256)\n        self.transform_seg = A.Compose([\n            A.Resize(IMG_SIZE_SEG, IMG_SIZE_SEG),\n            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n            ToTensorV2()\n        ])\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        # Percorsi\n        img_name = str(self.df.loc[idx, \"US\"])\n        mask_name = str(self.df.loc[idx, \"MASK\"])\n        label = int(self.df.loc[idx, \"LABEL\"])\n        \n        # Carica Immagine e Maschera\n        img_path = os.path.join(self.root, img_name)\n        pil_img = Image.open(img_path).convert(\"RGB\")\n        np_img = np.array(pil_img)\n        \n        try:\n            mask_path = os.path.join(self.root, mask_name)\n            mask = np.array(Image.open(mask_path).convert(\"L\"))\n            mask = np.where(mask > 0, 1.0, 0.0).astype(np.float32)\n        except:\n            # Maschera nera se file non esiste (es. casi Normali)\n            mask = np.zeros((np_img.shape[0], np_img.shape[1]), dtype=np.float32)\n\n        # Input CLF\n        input_clf = self.transform_clf(pil_img)\n        \n        # Input SEG (con maschera ridimensionata per valutazione)\n        aug = self.transform_seg(image=np_img, mask=mask)\n        input_seg = aug['image']\n        target_mask = aug['mask'].unsqueeze(0)\n\n        return input_clf, input_seg, label, target_mask, np_img\n\n# Creiamo il Test Set (Stesso seed del training per evitare leakage)\nfrom sklearn.model_selection import train_test_split\ndf = pd.read_excel(EXCEL_PATH).dropna(subset=[\"US\", \"LABEL\"])\n_, val_df = train_test_split(df, stratify=df[\"LABEL\"], test_size=0.2, random_state=SEED)\n\ntest_loader = DataLoader(PipelineDataset(val_df, IMAGES_ROOT), batch_size=1, shuffle=False)\nprint(f\"Dataset Test pronto: {len(val_df)} immagini.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================\n# CELL 5 - REPORT NUMERICO COMPLETO\n# ============================================================\n\n# --- 1. CLASSIFICAZIONE ---\nprint(\"\\n=== RISULTATI TASK 1a (CLASSIFICAZIONE) ===\")\n# Calcolo Balanced Accuracy\nbal_acc = balanced_accuracy_score(results[\"true_labels\"], results[\"pred_labels\"])\nprint(f\"ðŸ”¥ Balanced Accuracy: {bal_acc:.4f}\")\n\nprint(classification_report(results[\"true_labels\"], results[\"pred_labels\"],\n                            target_names=[\"Benign\", \"Malignant\", \"Normal\"]))\n\n# Confusion Matrix\ncm = confusion_matrix(results[\"true_labels\"], results[\"pred_labels\"])\nplt.figure(figsize=(5,4))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n            xticklabels=[\"B\", \"M\", \"N\"], yticklabels=[\"B\", \"M\", \"N\"])\nplt.title(f\"Confusion Matrix (Bal Acc: {bal_acc:.4f})\")\nplt.ylabel(\"Ground Truth\")\nplt.xlabel(\"Prediction\")\nplt.show()\n\n# --- 2. SEGMENTAZIONE ---\ndf_res = pd.DataFrame({\n    \"True\": results[\"true_labels\"],\n    \"Pred\": results[\"pred_labels\"],\n    \"Dice\": results[\"dice_scores\"]\n})\n\n# A. Global Dice (Media su tutto il dataset, inclusi i sani)\ndice_global = df_res[\"Dice\"].mean()\n\n# B. Lesion Dice (Media solo sui casi che SONO veramente tumori)\n# Include gli 0.0 generati se il classificatore ha perso il tumore.\ndice_lesion = df_res[df_res[\"True\"] != 2][\"Dice\"].mean()\n\n# C. Conditional Dice (Media solo sui tumori che il classificatore ha TROVATO)\n# Esclude i falsi negativi. Misura la qualitÃ  pura della segmentazione quando si attiva.\ndice_tp = df_res[(df_res[\"True\"] != 2) & (df_res[\"Pred\"] != 2)][\"Dice\"].mean()\n\nprint(\"\\n=== RISULTATI TASK 1b (SEGMENTAZIONE) ===\")\nprint(f\"1. Global Dice Score (Pipeline Totale):       {dice_global:.4f}\")\nprint(f\"2. Lesion Dice Score (Efficacia sui Malati):  {dice_lesion:.4f}\")\nprint(f\"3. Conditional Dice (QualitÃ  pura U-Net):     {dice_tp:.4f}\")\n\n# Analisi Errori\nmissed = df_res[(df_res[\"True\"] != 2) & (df_res[\"Pred\"] == 2)]\nprint(f\"\\nAnalisi Errori Pipeline:\")\nprint(f\"Lesioni perse dal Classificatore (False Negatives): {len(missed)} su {len(df_res[df_res['True']!=2])} totali.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================\n# CELL 6 - VISUALIZZAZIONE GRAFICA\n# ============================================================\nnum_show = 5\nplt.figure(figsize=(15, 4*num_show))\n\nfor i in range(num_show):\n    img = results[\"images\"][i]\n    true_m = results[\"true_masks\"][i]\n    pred_m = results[\"pred_masks\"][i]\n    t_lbl = id2class[results[\"true_labels\"][i]]\n    p_lbl = id2class[results[\"pred_labels\"][i]]\n    dice = results[\"dice_scores\"][i]\n    \n    # Colore titolo (Verde=Corretto, Rosso=Sbagliato)\n    col = 'green' if t_lbl == p_lbl else 'red'\n    \n    plt.subplot(num_show, 3, i*3 + 1)\n    plt.imshow(img)\n    plt.title(f\"True: {t_lbl} | Pred: {p_lbl}\", color=col, fontweight='bold')\n    plt.axis('off')\n    \n    plt.subplot(num_show, 3, i*3 + 2)\n    plt.imshow(true_m, cmap='gray')\n    plt.title(\"Ground Truth\")\n    plt.axis('off')\n    \n    plt.subplot(num_show, 3, i*3 + 3)\n    plt.imshow(pred_m, cmap='gray')\n    plt.title(f\"Pipeline Mask (Dice: {dice:.2f})\")\n    plt.axis('off')\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}